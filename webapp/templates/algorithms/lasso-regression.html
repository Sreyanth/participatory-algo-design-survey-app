<div>
  <h2>{{ algo }}</h2>
  <h3 id="{{ algo|slugify }}-1">How does it work?</h3>
  <p>
    This algorithm is a type of
    <a href="#" onclick="handleContent('linear-regression')"
      >linear regression</a
    >. Additionally, if a factor is not important to predict the outcome, the
    algorithm will completely ignore its impact on the prediction.
  </p>

  <h3 id="{{ algo|slugify }}-2">Let's try an example</h3>
  <p>
    To illustrate how it works, let's take the example of predicting the sale
    price of a house listing.
  </p>

  <p>
    We first gather all the factors that we think should be associated with the
    sale prices, such as the location, age, size, the surrounding amenities of
    the house, and whether the home has painted walls, and so on.
  </p>

  <p>
    We can then fit a "linear" or a straight line to identify any relationship
    between the factors and the sale prices using the information on houses sold
    in the past.
  </p>

  <p class="text-center">
    <img src="/static/img/algorithms/lasso-regression.jpg" alt="" />
  </p>

  <p>
    For example, if we use only the size of the house, we can see in the graph
    that every additional 100 sqft increases the house price by about $90,000.
    Additionally, if the house is built with high-quality materials, it will
    raise the value by $60,000. A linear regression algorithm might then look
    like this:
  </p>

  <pre><code>Predicted price = -50,000 + 90,000 * living area + 60,000 * (if quality materials) + ...</code></pre>

  <p>
    So, if the house we want to sell has an area of 1000 sq.ft and is built with
    high-quality materials, the house prediction will be: <br />
    <code
      >-50,000 + 90,000 * 10 (the area of the house in 100sq.ft) + 60,000 * 1 =
      910,000</code
    >
  </p>

  <p>
    However, unlike the regular linear regression model, this algorithm will
    <strong>drop factors that it considers trivial to the prediction</strong>.
    In this case, the algorithm considers the impact of the garage area and
    subsequently drops it from its consideration.
  </p>

  <p>
    Although this may seem bad at first because it lowers the value slightly,
    the algorithm can make better predictions for many houses because it can
    focus on finding more meaningful relationships between the factors and price
    by ignoring trivial factors.
  </p>

  <h3 id="{{ algo|slugify }}-3">Advantages</h3>
  <p>
    The advantage of this algorithm is that it is
    <strong>simple to implement</strong> and
    <strong>easy to explain</strong> the outcome predictions by using the
    weights associated with each factor.
    <strong
      >It performs better than linear regression when there are outliers</strong
    >. Because the algorithm disregards information it deems unimportant,
    <strong>it generalizes and performs better</strong> for houses it has never
    seen than linear regression.
  </p>
  <h3 id="{{ algo|slugify }}-4">Disadvantages</h3>
  <p>
    However, it suffers from the same drawbacks as
    <a href="#" onclick="handleContent('linear-regression')"
      >linear regression</a
    >. Because it drops factors that do not contribute to the performance of the
    prediction, it
    <strong
      >may drop factors that you may feel should be part of the consideration
      regardless</strong
    >. For example, the algorithm will think whether the house has painted walls
    does not matter to the sales price. However, you may feel very strongly
    about it and would like to include it in your decision-making anyway.
    <strong>It is slightly more difficult to interpret</strong> than linear
    regression because we need justification for why some factors are excluded
    but easier than other models.
  </p>
  <h3 id="{{ algo|slugify }}-5">Curious to learn more?</h3>
  <p>
    You can learn more about this algorithm
    <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)" target="_blank"
      >here</a
    >!
  </p>
</div>
