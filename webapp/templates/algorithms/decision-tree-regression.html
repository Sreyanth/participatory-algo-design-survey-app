<div>
  <h2>{{ algo }}</h2>
  <h3 id="{{ algo|slugify }}-1">How does it work?</h3>
  <p>
    If you have ever thought to yourself, "if the weather is hot, I will go to
    the beach, and if it is not, I will not go," then you have used a decision
    tree for making decisions. Intuitively, this algorithm is very similar to
    making everyday decisions using "if-this-then-that" rules. As we consider
    more factors, the algorithm keeps asking more such questions until it has
    considered all the elements to reach a final prediction.
  </p>
  <h3 id="{{ algo|slugify }}-2">Let's try an example</h3>
  <p>
    To illustrate how it works, let's take the example of predicting the sale
    price of a house listing.
  </p>

  <p>
    <img src="/static/img/algorithms/decision-tree-regression.jpg" alt="" />
  </p>

  <p>
    We first gather all the factors that we think should be associated with the
    sale prices, such as the location, age, size, the surrounding amenities of
    the house, and whether the home has painted walls, and so on.
  </p>

  <p>
    The algorithm will then make rules based on what factors distinguish a cheap
    house from an expensive one. For example, if the house is larger than 1400
    square feet, it will be on the pricier side and the cheaper side otherwise.
    Next, if a house is more than 1400 square feet and has high-quality
    materials, it will be approximately $706,000, and it will be about $412,000
    if the materials used are of not so good quality. The list can go on.
  </p>

  <p>
    To predict a price for the house we are selling, the algorithm will walk
    through a tree-like flowchart. After it reaches the bottom of the chart, we
    will know what price the house should have.
  </p>

  <h3 id="{{ algo|slugify }}-3">Advantages</h3>
  <p>
    The biggest advantage of the algorithm is that it is
    <strong>intuitive and easy</strong> to explain. As its name suggests, you
    can draw a decision tree showing exactly how a decision is made. It is also
    <strong>better at capturing complex relationships</strong> among the pricing
    factors and <strong>performs better</strong> than linear regressions in some
    instances when such relationships exist.
  </p>
  <h3 id="{{ algo|slugify }}-4">Disadvantages</h3>
  <p>
    Since the algorithm builds the decision rules based on the houses it has
    seen, it can perform worse for houses it has never seen.
  </p>
  <h3 id="{{ algo|slugify }}-5">Curious to learn more?</h3>
  <p>
    You can learn more about the algorithm
    <a
      href="https://en.wikipedia.org/wiki/Decision_tree_learning"
      target="_blank"
      >here</a
    >!
  </p>
</div>
